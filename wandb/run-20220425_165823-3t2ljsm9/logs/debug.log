2022-04-25 16:58:23,955 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Loading settings from C:\Users\mahdi\.config\wandb\settings
2022-04-25 16:58:23,955 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Loading settings from C:\Users\mahdi\Desktop\Github_Work\1\RSNA-Bone-Age\wandb\settings
2022-04-25 16:58:23,955 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Loading settings from environment variables: {}
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Inferring run settings from compute environment: {'program_relpath': 'Run.py', 'program': 'c:\\Users\\mahdi\\Desktop\\Github_Work\\1\\RSNA-Bone-Age\\Run.py'}
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Applying login settings: {'api_key': '***REDACTED***'}
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_setup.py:_flush():75] Applying login settings: {'api_key': '***REDACTED***'}
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_init.py:_log_setup():438] Logging user logs to C:\Users\mahdi\Desktop\Github_Work\1\RSNA-Bone-Age\wandb\run-20220425_165823-3t2ljsm9\logs\debug.log
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_init.py:_log_setup():439] Logging internal logs to C:\Users\mahdi\Desktop\Github_Work\1\RSNA-Bone-Age\wandb\run-20220425_165823-3t2ljsm9\logs\debug-internal.log
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_init.py:init():472] calling init triggers
2022-04-25 16:58:23,956 INFO    MainThread:20688 [wandb_init.py:init():475] wandb.init called with sweep_config: {}
config: {}
2022-04-25 16:58:23,957 INFO    MainThread:20688 [wandb_init.py:init():525] starting backend
2022-04-25 16:58:23,957 INFO    MainThread:20688 [backend.py:_multiprocessing_setup():99] multiprocessing start_methods=spawn, using: spawn
2022-04-25 16:58:23,966 INFO    MainThread:20688 [backend.py:ensure_launched():219] starting backend process...
2022-04-25 16:58:24,069 INFO    MainThread:20688 [backend.py:ensure_launched():224] started backend process with pid: 14292
2022-04-25 16:58:24,069 INFO    MainThread:20688 [wandb_init.py:init():534] backend started and connected
2022-04-25 16:58:24,075 INFO    MainThread:20688 [wandb_init.py:init():598] updated telemetry
2022-04-25 16:58:24,133 INFO    MainThread:20688 [wandb_init.py:init():629] communicating run to backend with 30 second timeout
2022-04-25 16:58:26,521 INFO    MainThread:20688 [wandb_run.py:_on_init():1922] communicating current version
2022-04-25 16:58:27,375 INFO    MainThread:20688 [wandb_run.py:_on_init():1926] got version response upgrade_message: "wandb version 0.12.15 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2022-04-25 16:58:27,375 INFO    MainThread:20688 [wandb_init.py:init():660] starting run threads in backend
2022-04-25 16:58:27,985 INFO    MainThread:20688 [wandb_run.py:_console_start():1896] atexit reg
2022-04-25 16:58:27,985 INFO    MainThread:20688 [wandb_run.py:_redirect():1769] redirect: SettingsConsole.WRAP
2022-04-25 16:58:27,986 INFO    MainThread:20688 [wandb_run.py:_redirect():1806] Wrapping output streams.
2022-04-25 16:58:27,989 INFO    MainThread:20688 [wandb_run.py:_redirect():1830] Redirects installed.
2022-04-25 16:58:27,989 INFO    MainThread:20688 [wandb_init.py:init():685] run started, returning control to user process
2022-04-25 16:58:27,992 INFO    MainThread:20688 [wandb_run.py:_config_callback():1129] config_cb None None {'net': 'MobileNetV2_Pre2(\n  (mobilenet_v2): MobileNetV2(\n    (features): Sequential(\n      (0): ConvNormActivation(\n        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): ConvNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n      (0): ReLU()\n      (1): Dropout(p=0.2, inplace=False)\n      (2): Linear(in_features=1281, out_features=512, bias=True)\n      (3): ReLU()\n      (4): Dropout(p=0.5, inplace=False)\n      (5): Linear(in_features=512, out_features=229, bias=True)\n    )\n  )\n)', 'epochs': 10, 'batch_size': 2, 'learning_rate': 0.001, 'save_checkpoint': True, 'amp': False, 'model': 'MobileNetV2_Pre2', 'name': '20220425_165820_MobileNetV2_Pre2', 'device': 'cuda', 'optimizer': 'Adam', 'criterion': 'BCEWithLogitsLoss'}
2022-04-25 16:58:27,994 INFO    MainThread:20688 [wandb_run.py:_tensorboard_callback():1242] tensorboard callback: tensorboard\20220425_165820_MobileNetV2_Pre2, True
2022-04-25 17:04:38,436 INFO    MainThread:20688 [wandb_run.py:_atexit_cleanup():1865] got exitcode: 255
2022-04-25 17:04:38,437 INFO    MainThread:20688 [wandb_run.py:_restore():1837] restore
2022-04-25 17:04:39,095 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 2
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 16320
}

2022-04-25 17:04:39,227 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 2
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 16320
}

2022-04-25 17:04:44,356 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: None
2022-04-25 17:04:45,515 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 2
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 16320
}

2022-04-25 17:04:46,507 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 2
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 16320
}

2022-04-25 17:04:47,092 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,211 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,319 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,429 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,540 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,648 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,759 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,867 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:47,976 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:48,084 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 16320
  total_bytes: 37760
}

2022-04-25 17:04:48,194 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 33192
  total_bytes: 37760
}

2022-04-25 17:04:48,304 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37544
  total_bytes: 37760
}

2022-04-25 17:04:48,410 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37544
  total_bytes: 37760
}

2022-04-25 17:04:48,517 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37544
  total_bytes: 37760
}

2022-04-25 17:04:48,626 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:48,735 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:48,844 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:48,952 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:49,060 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:49,168 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:49,691 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}

2022-04-25 17:04:51,235 INFO    MainThread:20688 [wandb_run.py:_on_finish():1995] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 6
  other_count: 1
}
pusher_stats {
  uploaded_bytes: 37760
  total_bytes: 37760
}
local_info {
}

2022-04-25 17:04:52,385 INFO    MainThread:20688 [wandb_run.py:_footer_history_summary_info():3087] rendering history
2022-04-25 17:04:52,385 INFO    MainThread:20688 [wandb_run.py:_footer_history_summary_info():3116] rendering summary
2022-04-25 17:04:52,396 INFO    MainThread:20688 [wandb_run.py:_footer_sync_info():3044] logging synced files
