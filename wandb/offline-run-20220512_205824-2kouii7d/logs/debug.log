2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_setup.py:_flush():71] setting env: {}
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_setup.py:_flush():71] setting login settings: {'api_key': '***REDACTED***'}
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_init.py:_log_setup():371] Logging user logs to G:\Samei\Repo\RSNA-Bone-Age\wandb\offline-run-20220512_205824-2kouii7d\logs\debug.log
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_init.py:_log_setup():372] Logging internal logs to G:\Samei\Repo\RSNA-Bone-Age\wandb\offline-run-20220512_205824-2kouii7d\logs\debug-internal.log
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_init.py:init():404] calling init triggers
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_init.py:init():409] wandb.init called with sweep_config: {}
config: {}
2022-05-12 20:58:24,789 INFO    MainThread:15344 [wandb_init.py:init():460] starting backend
2022-05-12 20:58:24,789 INFO    MainThread:15344 [backend.py:_multiprocessing_setup():99] multiprocessing start_methods=spawn, using: spawn
2022-05-12 20:58:24,805 INFO    MainThread:15344 [backend.py:ensure_launched():216] starting backend process...
2022-05-12 20:58:24,867 INFO    MainThread:15344 [backend.py:ensure_launched():221] started backend process with pid: 7616
2022-05-12 20:58:24,867 INFO    MainThread:15344 [wandb_init.py:init():469] backend started and connected
2022-05-12 20:58:24,867 INFO    MainThread:15344 [wandb_init.py:init():533] updated telemetry
2022-05-12 20:58:24,914 INFO    MainThread:15344 [wandb_init.py:init():606] starting run threads in backend
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_console_start():1810] atexit reg
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_redirect():1684] redirect: SettingsConsole.WRAP
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_redirect():1721] Wrapping output streams.
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_redirect():1745] Redirects installed.
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_init.py:init():633] run started, returning control to user process
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_config_callback():956] config_cb None None {'net': 'MobileNetV2_Pre2(\n  (mobilenet_v2): MobileNetV2(\n    (features): Sequential(\n      (0): ConvNormActivation(\n        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n        (conv): Sequential(\n          (0): ConvNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): ConvNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n      (0): ReLU()\n      (1): Dropout(p=0.2, inplace=False)\n      (2): Linear(in_features=1281, out_features=512, bias=True)\n      (3): ReLU()\n      (4): Dropout(p=0.5, inplace=False)\n      (5): Linear(in_features=512, out_features=229, bias=True)\n    )\n  )\n)', 'epochs': 50, 'batch_size': 20, 'learning_rate': 0.001, 'save_checkpoint': False, 'amp': False, 'model': 'MobileNetV2_Pre2', 'name': '20220512_205824_MobileNetV2_Pre2', 'device': 'cuda', 'optimizer': 'Adam', 'criterion': 'BCEWithLogitsLoss'}
2022-05-12 20:58:27,883 INFO    MainThread:15344 [wandb_run.py:_tensorboard_callback():1029] tensorboard callback: tensorboard\20220512_205824_MobileNetV2_Pre2, None
