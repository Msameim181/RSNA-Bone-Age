wandb_version: 1

WandB_usage:
  desc: null
  value: true
_wandb:
  desc: null
  value:
    cli_version: 0.12.9
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.5
    start_time: 1653249164
    t:
      1:
      - 1
      2:
      - 1
      3:
      - 4
      - 13
      - 15
      4: 3.8.5
      5: 0.12.9
      8:
      - 3
      - 5
amp:
  desc: null
  value: false
basedOnSex:
  desc: null
  value: true
batch_size:
  desc: null
  value: 8
criterion:
  desc: null
  value: BCEWithLogitsLoss
dataset_name:
  desc: null
  value: rsna-bone-age-kaggle
device:
  desc: null
  value: cuda
epochs:
  desc: null
  value: 20
gender:
  desc: null
  value: female
learning_rate:
  desc: null
  value: 0.001
model:
  desc: null
  value: MobileNetV2_Pre_female
name:
  desc: null
  value: 20220523_002243_MobileNetV2_Pre_female
net:
  desc: null
  value: "MobileNetV2(\n  (mobilenet_v2): MobileNetV2(\n    (features): Sequential(\n\
    \      (0): ConvNormActivation(\n        (0): Conv2d(1, 32, kernel_size=(3, 3),\
    \ stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05,\
    \ momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n\
    \      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n        \
    \  (0): ConvNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3),\
    \ stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          \
    \  (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1,\
    \ 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n       \
    \     (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1,\
    \ 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1,\
    \ 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1,\
    \ 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      \
    \      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1,\
    \ 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n     \
    \       (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n     \
    \       (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n\
    \        (conv): Sequential(\n          (0): ConvNormActivation(\n           \
    \ (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n     \
    \       (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \            (2): ReLU6(inplace=True)\n          )\n          (1): ConvNormActivation(\n\
    \            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n\
    \          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1),\
    \ bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n        )\n      )\n      (18): ConvNormActivation(\n\
    \        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\
    \        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n\
    \      (0): Linear(in_features=1280, out_features=512, bias=True)\n      (1):\
    \ ReLU()\n      (2): Linear(in_features=512, out_features=229, bias=True)\n  \
    \  )\n  )\n)"
optimizer:
  desc: null
  value: Adam
save_checkpoint:
  desc: null
  value: true
test_dataset_size:
  desc: null
  value: 100
train_dataset_size:
  desc: null
  value: 5778
