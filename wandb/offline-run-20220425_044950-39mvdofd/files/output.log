INFO: WandB setup completed.
INFO: Training Settings:
        Device:             cuda
        Model:              MobileNetV2_Pre2
        Image Channel:      1
        Epochs:             10
        Batch Size:         2
        Learning Rate:      0.001
        Training Size:      8828
        validation Size:    3783
        validation %:       0.3
        Checkpoints:        True
        Mixed Precision:    False
        optimizer:          Adam
        criterion:          BCEWithLogitsLoss
INFO: Start training as "20220425_044950_MobileNetV2_Pre2" ...
Epoch 1/10:  37%|█████████████████████████████████████▍                                                              | 3304/8828 [04:28<07:28, 12.32img/s, Epoch Loss (Train)=0.012, Step Loss (Batch)=0.0193]
Traceback (most recent call last):
  File "c:\Users\mahdi\Desktop\Github_Work\1\RSNA-Bone-Age\Run.py", line 86, in <module>
    trainer(
  File "c:\Users\mahdi\Desktop\Github_Work\1\RSNA-Bone-Age\Train.py", line 128, in trainer
    grad_scaler.scale(loss).backward()
  File "C:\Python\Python39\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Python\Python39\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt