diff --git a/Run.py b/Run.py
index 40e19ed..556f215 100644
--- a/Run.py
+++ b/Run.py
@@ -45,7 +45,7 @@ if __name__ == '__main__':
 
     # Loading NN model
     logging.info('Loading NN Model...')
-    net = ResNet50(pretrained = True, image_channels=1, num_classes=num_classes)
+    net = ResNet18(pretrained = True, image_channels=1, num_classes=num_classes)
     logging.info(f'Model loaded as "{net.name}"')
     logging.info(f'Network:\n'
                  f'\t{net.in_channels} input channels\n'
@@ -55,7 +55,7 @@ if __name__ == '__main__':
     logging.info('Reading hyperparameters...')
     learning_rate = 0.001
     epochs = 10
-    batch_size = 2
+    batch_size = 6
     val_percent = 0.3
     WandB_usage = True
 
diff --git a/utils/__pycache__/tensorboard_logger.cpython-39.pyc b/utils/__pycache__/tensorboard_logger.cpython-39.pyc
index a0f5daa..e1bc661 100644
Binary files a/utils/__pycache__/tensorboard_logger.cpython-39.pyc and b/utils/__pycache__/tensorboard_logger.cpython-39.pyc differ
diff --git a/utils/__pycache__/wandb_logger.cpython-39.pyc b/utils/__pycache__/wandb_logger.cpython-39.pyc
index 882779e..06109aa 100644
Binary files a/utils/__pycache__/wandb_logger.cpython-39.pyc and b/utils/__pycache__/wandb_logger.cpython-39.pyc differ
diff --git a/utils/tensorboard_logger.py b/utils/tensorboard_logger.py
index 03fea7d..e8484a7 100644
--- a/utils/tensorboard_logger.py
+++ b/utils/tensorboard_logger.py
@@ -2,7 +2,8 @@ import logging
 from pathlib import Path
 
 import torch
-from torch.utils.tensorboard import SummaryWriter
+# from torch.utils.tensorboard import SummaryWriter
+from tensorboardX import SummaryWriter
 
 def tb_setup(config, log_dir:str = './tensorboard/'):
     """
@@ -42,8 +43,8 @@ def tb_setup(config, log_dir:str = './tensorboard/'):
 
 def tb_log_training_step(tb_logger, loss, global_step, epoch, epoch_loss_step):
      # Logging
-    tb_logger.add_scalar('Loss/Step Loss', loss.item(), global_step)
-    tb_logger.add_scalar('Loss/Train Loss (Step)', epoch_loss_step, global_step)
+    tb_logger.add_scalar('Loss/Step_Loss', loss.item(), global_step)
+    tb_logger.add_scalar('Loss/Train_Loss_Step_', epoch_loss_step, global_step)
     tb_logger.add_scalar('Process/Step', global_step, global_step)
     tb_logger.add_scalar('Process/Epoch', epoch, global_step)
 
@@ -52,9 +53,9 @@ def tb_log_training_step(tb_logger, loss, global_step, epoch, epoch_loss_step):
 
 def tb_log_training(tb_logger, epoch_loss, val_loss, epoch):
     # Logging
-    tb_logger.add_scalar('Loss/Validation Loss (Epoch)', val_loss, epoch)
-    tb_logger.add_scalar('Loss/Train Loss', epoch_loss, epoch)
-    tb_logger.add_scalar('Loss/Epoch Loss', epoch_loss, epoch)
+    tb_logger.add_scalar('Loss/Validation_Loss_Epoch_', val_loss, epoch)
+    tb_logger.add_scalar('Loss/Train_Loss', epoch_loss, epoch)
+    tb_logger.add_scalar('Loss/Epoch_Loss', epoch_loss, epoch)
     logging.info(f'\nEpoch: {epoch + 1} | Train Loss: {epoch_loss:.4f} | Validation Loss: {val_loss:.4f}\n')
 
     tb_logger.flush()
@@ -64,10 +65,10 @@ def tb_log_training(tb_logger, epoch_loss, val_loss, epoch):
 def tb_log_validation(tb_logger, optimizer, val_loss, acc, 
     images, batch_size, global_step, epoch, net):
     # TensorBoard Storing the results
-    tb_logger.add_scalar('Process/Learning Rate', optimizer.param_groups[0]['lr'], global_step)
-    tb_logger.add_scalar('Loss/Validation Loss (Step)', val_loss, global_step)
-    tb_logger.add_scalar('Accuracy/Validation Correct (Step)', acc, global_step)
-    tb_logger.add_scalar('Accuracy/Correct %', acc * 100, global_step)
+    tb_logger.add_scalar('Process/Learning_Rate', optimizer.param_groups[0]['lr'], global_step)
+    tb_logger.add_scalar('Loss/Validation_Loss_Step_', val_loss, global_step)
+    tb_logger.add_scalar('Accuracy/Validation_Correct_Step_', acc, global_step)
+    tb_logger.add_scalar('Accuracy/Correct_P', acc * 100, global_step)
     tb_logger.add_scalar('Process/Step', global_step, global_step)
     tb_logger.add_scalar('Process/Epoch', epoch, global_step)
     # img_batch = images.cpu() if batch_size == 1 else [image.cpu() for image in images]
diff --git a/utils/wandb_logger.py b/utils/wandb_logger.py
index 313d393..3748990 100644
--- a/utils/wandb_logger.py
+++ b/utils/wandb_logger.py
@@ -17,7 +17,7 @@ def wandb_setup(config) -> wandb:
     wandb_logger = wandb.init(
         project = "Bone-Age-RSNA", 
         entity = "rsna-bone-age", 
-        sync_tensorboard = True,
+        # sync_tensorboard = True,
         name = run_name, 
         tags = [
             'bone-age', 
@@ -27,7 +27,7 @@ def wandb_setup(config) -> wandb:
             f'{device}'
         ],)
     
-    # wandb.tensorboard.patch(root_logdir="./tensorboard", tensorboardX=True)
+    wandb.tensorboard.patch(root_logdir="./tensorboard", tensorboard_x=True)
     # Configure wandb
     wandb_logger.config.update(config)
     # Logging
@@ -38,9 +38,9 @@ def wandb_setup(config) -> wandb:
 def wandb_log_training_step(wandb_logger, loss, global_step, epoch, epoch_loss_step):
     # Logging
     wandb_logger.log({
-        'Loss/Step_Loss':            loss.item(),
+        'Loss/Step Loss':            loss.item(),
         'Process/Step':                 global_step,
-        'Loss/Train_Loss_(Step)':    epoch_loss_step,
+        'Loss/Train Loss (Step)':    epoch_loss_step,
         'Process/Epoch':                epoch
     })
 
